{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cvae_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLJQ6clbaZ61Wa1QLQd797",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felix0097/CVAE_mnist/blob/master/cvae_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwVSjrch0s2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDvrEbJm2soK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHNGsCTqYVyV",
        "colab_type": "text"
      },
      "source": [
        "**Define Convolutional CVAE model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdh6QpFh09Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvCVAE(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, \n",
        "               input_shape_img: Tuple[int, int, int],\n",
        "               input_shape_cond: int, \n",
        "               latent_dim: int):\n",
        "\n",
        "    super(ConvCVAE, self).__init__()\n",
        "\n",
        "    self.input_shape_img = input_shape_img\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "    self.conv_enc = tf.keras.Sequential(\n",
        "        [tf.keras.layers.InputLayer(input_shape=input_shape_img),\n",
        "         tf.keras.layers.Conv2D(filters=32, \n",
        "                                kernel_size=3, \n",
        "                                activation='relu',\n",
        "                                padding='same'),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                      padding='same'),\n",
        "         tf.keras.layers.Conv2D(filters=64, \n",
        "                                kernel_size=3,\n",
        "                                activation='relu',\n",
        "                                padding='same'),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                      padding='same'),\n",
        "         tf.keras.layers.Flatten()\n",
        "      ],\n",
        "      name='encoder')\n",
        "    \n",
        "    self.enc = tf.keras.Sequential(\n",
        "        [tf.keras.layers.InputLayer(input_shape=self.conv_enc.output_shape[1] + input_shape_cond),\n",
        "         tf.keras.layers.Dense(20*latent_dim,\n",
        "                               activation='relu'),\n",
        "         tf.keras.layers.Dense(2*latent_dim)]\n",
        "    )\n",
        "\n",
        "    self.dec = tf.keras.Sequential(\n",
        "        [tf.keras.layers.InputLayer(input_shape=(latent_dim + input_shape_cond)),\n",
        "         tf.keras.layers.Dense(units=self.conv_enc.output_shape[1],\n",
        "                               activation=tf.nn.relu),\n",
        "         tf.keras.layers.Reshape(target_shape=self.conv_enc.layers[-2].output_shape[1:]),\n",
        "         tf.keras.layers.Conv2DTranspose(filters=64,\n",
        "                                         kernel_size=3,\n",
        "                                         activation='relu',\n",
        "                                         padding='same'),\n",
        "         tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
        "         tf.keras.layers.Conv2DTranspose(filters=32,\n",
        "                                         kernel_size=3,\n",
        "                                         activation='relu',\n",
        "                                         padding='same'),\n",
        "         tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
        "         tf.keras.layers.Conv2DTranspose(filters=input_shape_img[2], \n",
        "                                         kernel_size=3, \n",
        "                                         strides=(1, 1),\n",
        "                                         padding='same'),\n",
        "         tf.keras.layers.Activation('sigmoid')\n",
        "        ],\n",
        "        name='decoder')\n",
        "    \n",
        "    def call(self, inputs, training=False):\n",
        "\n",
        "      img_input = inputs[0]\n",
        "      cond_input = inputs[1]\n",
        "\n",
        "      enc_img = self.conv_enc(img_input)\n",
        "      enc_output = self.enc(tf.concat([enc_img, cond_input], axis=1))\n",
        "      mean, log_scale = tf.split(enc_output, num_or_size_splits=2, axis=1)\n",
        "      scale= tf.math.exp(log_scale)\n",
        "\n",
        "      latent_dist = tfp.distributions.MultivariateNormalDiag(loc=mean,\n",
        "                                                             scale_diag=scale)\n",
        "      \n",
        "      ref_dist = tfp.distributions.MultivariateNormalDiag(loc=tf.zeros(self.latent_dim))\n",
        "\n",
        "      kl_divergence = tfp.distributions.kl_divergence(latent_dist, ref_dist)\n",
        "      self.add_loss(tf.math.reduce_sum(kl_divergence, name='KL_divergence_loss'))\n",
        "\n",
        "      input_dec = tf.concat([latent_dist.sample(), cond_input], axis=1)\n",
        "      dec_img = self.dec(input_dec)\n",
        "      dec_img = tf.image.resize_with_crop_or_pad(dec_img, \n",
        "                                                 self.input_shape_img[0],\n",
        "                                                 self.input_shape_img[1])\n",
        "      \n",
        "      return dec_img\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZJjtbCWYe01",
        "colab_type": "text"
      },
      "source": [
        "**Prepare data set for fitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aeJiQ9cYkUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(elem):\n",
        "    img = elem['image']\n",
        "    label = elem['label']\n",
        "    # convert input image to [0, 1]\n",
        "    img = tf.cast(img, dtype=tf.float32) / tf.cast(255., dtype=tf.float32)\n",
        "    # one hot encode label\n",
        "    label = tf.one_hot(tf.cast(label, dtype=tf.uint8), depth=10)\n",
        "\n",
        "    return ((img, label), img)\n",
        "\n",
        "ds_train = tfds.load(name=\"mnist\", split=\"train\")\n",
        "ds_val = tfds.load(name=\"mnist\", split=\"test\")\n",
        "\n",
        "ds_train = ds_train.map(preprocess_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_val = ds_val.map(preprocess_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_train = ds_train.shuffle(5000, reshuffle_each_iteration=True)\\\n",
        "                   .repeat()\\\n",
        "                   .batch(64)\\\n",
        "                   .prefetch(64)\n",
        "ds_val = ds_val.shuffle(5000)\\\n",
        "               .repeat()\\\n",
        "               .batch(64)\\\n",
        "               .prefetch(64)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWkGDnOEYklO",
        "colab_type": "text"
      },
      "source": [
        "**Fit model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq9m-YEHnlPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7a36627-bcce-4828-ee26-9266e28cb5ed"
      },
      "source": [
        "ds_train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: (((None, 28, 28, 1), (None, 10)), (None, 28, 28, 1)), types: ((tf.float32, tf.float32), tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOZPNn601ahL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "0b7355e0-d391-4ff9-9fc6-1312396b7d93"
      },
      "source": [
        "conv_cvae = ConvCVAE(input_shape_img=(28, 28, 1),\n",
        "                     input_shape_cond=10,\n",
        "                     latent_dim=10)\n",
        "\n",
        "conv_cvae.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy())\n",
        "\n",
        "conv_cvae.fit(ds_train,\n",
        "              validation_data=ds_val,\n",
        "              epochs=10\n",
        "              )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f5807daa54c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m conv_cvae.fit(ds_train,\n\u001b[1;32m      9\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m               )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2358\u001b[0m     \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2361\u001b[0m       \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_from_inputs\u001b[0;34m(self, all_inputs, target, orig_inputs, orig_target)\u001b[0m\n\u001b[1;32m   2578\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m         target = training_utils.cast_if_floating_dtype_and_mismatch(\n\u001b[0;32m-> 2580\u001b[0;31m             target, self.outputs)\n\u001b[0m\u001b[1;32m   2581\u001b[0m       training_utils.validate_input_types(target, orig_target,\n\u001b[1;32m   2582\u001b[0m                                           allow_dict=False, field_name='target')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcast_if_floating_dtype_and_mismatch\u001b[0;34m(targets, outputs)\u001b[0m\n\u001b[1;32m   1334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;31m# There is one target, so output[0] should be the only output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast_single_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m   \u001b[0mnew_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dtype'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpaGvwIq7EHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}